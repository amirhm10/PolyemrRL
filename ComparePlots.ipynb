{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:30.568893Z",
     "start_time": "2026-01-08T03:10:29.730604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Simulation.mpc import *\n",
    "from Simulation.system_functions import PolymerCSTR\n",
    "from utils.helpers import *"
   ],
   "id": "e4ff3e97345158b8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize the system",
   "id": "50e6ae2406a60f62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:30.575656Z",
     "start_time": "2026-01-08T03:10:30.573013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First initiate the system\n",
    "# Parameters\n",
    "Ad = 2.142e17           # h^-1\n",
    "Ed = 14897              # K\n",
    "Ap = 3.816e10           # L/(molh)\n",
    "Ep = 3557               # K\n",
    "At = 4.50e12            # L/(molh)\n",
    "Et = 843                # K\n",
    "fi = 0.6                # Coefficient\n",
    "m_delta_H_r = -6.99e4   # j/mol\n",
    "hA = 1.05e6             # j/(Kh)\n",
    "rhocp = 1506            # j/(Kh)\n",
    "rhoccpc = 4043          # j/(Kh)\n",
    "Mm = 104.14             # g/mol\n",
    "system_params = np.array([Ad, Ed, Ap, Ep, At, Et, fi, m_delta_H_r, hA, rhocp, rhoccpc, Mm])"
   ],
   "id": "b720b0f824c8908a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:30.655474Z",
     "start_time": "2026-01-08T03:10:30.652562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Design Parameters\n",
    "CIf = 0.5888    # mol/L\n",
    "CMf = 8.6981    # mol/L\n",
    "Qi = 108.       # L/h\n",
    "Qs = 459.       # L/h\n",
    "Tf = 330.       # K\n",
    "Tcf = 295.      # K\n",
    "V = 3000.       # L\n",
    "Vc = 3312.4     # L\n",
    "\n",
    "system_design_params = np.array([CIf, CMf, Qi, Qs, Tf, Tcf, V, Vc])"
   ],
   "id": "83d58cc4018a5e2b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:30.669035Z",
     "start_time": "2026-01-08T03:10:30.666946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Steady State Inputs\n",
    "Qm_ss = 378.    # L/h\n",
    "Qc_ss = 471.6   # L/h\n",
    "\n",
    "system_steady_state_inputs = np.array([Qc_ss, Qm_ss])"
   ],
   "id": "cb195d914ba0ce0e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:30.781953Z",
     "start_time": "2026-01-08T03:10:30.779759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sampling time of the system\n",
    "delta_t = 0.5 # 30 mins"
   ],
   "id": "661346fda19c27ce",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:30.930213Z",
     "start_time": "2026-01-08T03:10:30.927710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initiate the CSTR for steady state values\n",
    "cstr = PolymerCSTR(system_params, system_design_params, system_steady_state_inputs, delta_t)\n",
    "steady_states={\"ss_inputs\":cstr.ss_inputs,\n",
    "               \"y_ss\":cstr.y_ss}"
   ],
   "id": "ca8ba0b3c2c5c408",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the system matrices, min max scaling, and min max of the states",
   "id": "96298b2ac56b1e35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:31.260499Z",
     "start_time": "2026-01-08T03:10:31.258128Z"
    }
   },
   "cell_type": "code",
   "source": "dir_path = os.path.join(os.getcwd(), \"Data\")",
   "id": "ffa07c42e59a659e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:31.437696Z",
     "start_time": "2026-01-08T03:10:31.433931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Defining the range of setpoints for data generation\n",
    "setpoint_y = np.array([[3.2, 321],\n",
    "                       [4.5, 325]])\n",
    "u_min = np.array([71.6, 78])\n",
    "u_max = np.array([870, 670])\n",
    "\n",
    "system_data = load_and_prepare_system_data(steady_states=steady_states, setpoint_y=setpoint_y, u_min=u_min, u_max=u_max)"
   ],
   "id": "2b933cce6a53dbb4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:31.626285Z",
     "start_time": "2026-01-08T03:10:31.623843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A_aug = system_data[\"A_aug\"]\n",
    "B_aug = system_data[\"B_aug\"]\n",
    "C_aug = system_data[\"C_aug\"]"
   ],
   "id": "14d83865649d3820",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:31.784525Z",
     "start_time": "2026-01-08T03:10:31.782323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_min = system_data[\"data_min\"]\n",
    "data_max = system_data[\"data_max\"]"
   ],
   "id": "e5c0831b862c46fa",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:31.976452Z",
     "start_time": "2026-01-08T03:10:31.974275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_max_states = {'max_s': np.array([256.79686253, 256.01560603,  48.99447186, 144.79949103,\n",
    "          2.82199733,   3.14014989,   2.78866348,   3.71691422,\n",
    "          6.2029936 ]),\n",
    "                  'min_s': np.array([ -272.28060121, -1112.33972595,   -76.63993491,  -608.60327886,\n",
    "           -3.94399122,    -3.93115257,    -2.9532091 ,    -4.06547624,\n",
    "          -28.25906582])}"
   ],
   "id": "db713d88c94cef98",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:32.421362Z",
     "start_time": "2026-01-08T03:10:32.418962Z"
    }
   },
   "cell_type": "code",
   "source": "y_sp_scaled_deviation = system_data[\"y_sp_scaled_deviation\"]",
   "id": "926daea189ad7677",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:32.742592Z",
     "start_time": "2026-01-08T03:10:32.740558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b_min = system_data[\"b_min\"]\n",
    "b_max = system_data[\"b_max\"]"
   ],
   "id": "621724c0e49eaf0d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:33.061463Z",
     "start_time": "2026-01-08T03:10:33.058521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_max_dict = system_data[\"min_max_dict\"]\n",
    "min_max_dict[\"x_max\"] = np.array([256.79686253, 256.01560603,  48.99447186, 144.79949103,\n",
    "          2.82199733,   3.14014989,   2.78866348,   3.71691422,\n",
    "          6.2029936 ])\n",
    "min_max_dict[\"x_min\"] = np.array([ -272.28060121, -1112.33972595,   -76.63993491,  -608.60327886,\n",
    "           -3.94399122,    -3.93115257,    -2.9532091 ,    -4.06547624,\n",
    "          -28.25906582])"
   ],
   "id": "d9f12859fffb388f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:33.456070Z",
     "start_time": "2026-01-08T03:10:33.453072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setpoints in deviation form\n",
    "inputs_number = int(B_aug.shape[1])\n",
    "y_sp_scenario = np.array([[4.5, 324],\n",
    "                          [3.4, 321]])\n",
    "\n",
    "y_sp_scenario = (apply_min_max(y_sp_scenario, data_min[inputs_number:], data_max[inputs_number:])\n",
    "                 - apply_min_max(steady_states[\"y_ss\"], data_min[inputs_number:], data_max[inputs_number:]))\n",
    "n_tests = 200\n",
    "set_points_len = 400\n",
    "TEST_CYCLE = [False, False, False, False, False]\n",
    "warm_start = 10\n",
    "ACTOR_FREEZE = 10 * set_points_len\n",
    "warm_start_plot = warm_start * 2 * set_points_len + ACTOR_FREEZE"
   ],
   "id": "fc63f60c2a1cb195",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:33.969246Z",
     "start_time": "2026-01-08T03:10:33.953476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Observer Gain\n",
    "poles = np.array(np.array([0.44619852, 0.33547649, 0.36380595, 0.70467118, 0.3562966,\n",
    "                           0.42900673, 0.4228262 , 0.96916776, 0.91230187]))\n",
    "L = compute_observer_gain(A_aug, C_aug, poles)"
   ],
   "id": "42831ffadd108648",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The system is observable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Simulation\\mpc.py:124: UserWarning: Convergence was not reached after maxiter iterations.\n",
      "You asked for a tolerance of 0.001, we got 0.9999999422182038.\n",
      "  obs_gain_calc = signal.place_poles(A.T, C.T, desired_poles, method='KNV0')\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:10:34.549303Z",
     "start_time": "2026-01-08T03:10:34.540717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_reward_fn_relative_QR(\n",
    "        data_min, data_max, n_inputs,\n",
    "        k_rel, band_floor_phys,\n",
    "        Q_diag, R_diag,\n",
    "        tau_frac=0.7,\n",
    "        gamma_out=0.5, gamma_in=0.5,\n",
    "        beta=5.0, gate=\"geom\", lam_in=1.0,\n",
    "        bonus_kind=\"exp\", bonus_k=12.0, bonus_p=0.6, bonus_c=20.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reward with relative tracking bands.\n",
    "\n",
    "    data_min, data_max : arrays for [u_min..., y_min...], [u_max..., y_max...]\n",
    "    n_inputs           : number of inputs (so outputs start at index n_inputs)\n",
    "    k_rel              : per-output relative tolerance factors (same length as outputs)\n",
    "    band_floor_phys    : per-output minimum band in physical units\n",
    "    Q_diag, R_diag     : quadratic weights (same as before)\n",
    "    \"\"\"\n",
    "\n",
    "    data_min = np.asarray(data_min, float)\n",
    "    data_max = np.asarray(data_max, float)\n",
    "    dy = np.maximum(data_max[n_inputs:] - data_min[n_inputs:], 1e-12)  # phys range for each y\n",
    "\n",
    "    k_rel = np.asarray(k_rel, float)\n",
    "    band_floor_phys = np.asarray(band_floor_phys, float)\n",
    "    Q_diag = np.asarray(Q_diag, float)\n",
    "    R_diag = np.asarray(R_diag, float)\n",
    "\n",
    "    # floor in *scaled* coordinates (used if y_sp_phys is not provided)\n",
    "    band_floor_scaled = band_floor_phys / np.maximum(dy, 1e-12)\n",
    "\n",
    "    def _sigmoid(x):\n",
    "        x = np.clip(x, -60.0, 60.0)\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    def _phi(z, kind=bonus_kind, k=bonus_k, p=bonus_p, c=bonus_c):\n",
    "        z = np.clip(z, 0.0, 1.0)\n",
    "        if kind == \"linear\":\n",
    "            return 1.0 - z\n",
    "        if kind == \"quadratic\":\n",
    "            return (1.0 - z) ** 2\n",
    "        if kind == \"exp\":\n",
    "            return (np.exp(-k * z) - np.exp(-k)) / (1.0 - np.exp(-k))\n",
    "        if kind == \"power\":\n",
    "            return 1.0 - np.power(z, p)\n",
    "        if kind == \"log\":\n",
    "            return np.log1p(c * (1.0 - z)) / np.log1p(c)\n",
    "        raise ValueError(\"unknown bonus kind\")\n",
    "\n",
    "    def reward_fn(e_scaled, du_scaled, y_sp_phys=None):\n",
    "        \"\"\"\n",
    "        e_scaled : output error in scaled deviation space  (same as before)\n",
    "        du_scaled: input move in scaled deviation space    (same as before)\n",
    "        y_sp_phys: current setpoint in *physical* units (array len = n_outputs)\n",
    "        \"\"\"\n",
    "\n",
    "        e_scaled = np.asarray(e_scaled, float)\n",
    "        du_scaled = np.asarray(du_scaled, float)\n",
    "\n",
    "        # ----- dynamic band based on setpoint -----\n",
    "        if y_sp_phys is None:\n",
    "            # fallback: just use the floor\n",
    "            band_scaled = band_floor_scaled\n",
    "        else:\n",
    "            y_sp_phys_arr = np.asarray(y_sp_phys, float)\n",
    "            # band_phys_i = max(k_rel_i * |y_sp_i|, band_floor_phys_i)\n",
    "            band_phys = np.maximum(k_rel * np.abs(y_sp_phys_arr), band_floor_phys)\n",
    "            band_scaled = band_phys / np.maximum(dy, 1e-12)\n",
    "\n",
    "        tau_scaled = tau_frac * band_scaled\n",
    "\n",
    "        # ----- inside/outside gate -----\n",
    "        abs_e = np.abs(e_scaled)\n",
    "        s_i = _sigmoid((band_scaled - abs_e) / np.maximum(tau_scaled, 1e-12))\n",
    "\n",
    "        if gate == \"prod\":\n",
    "            w_in = float(np.prod(s_i, dtype=np.float64))\n",
    "        elif gate == \"mean\":\n",
    "            w_in = float(np.mean(s_i))\n",
    "        elif gate == \"geom\":\n",
    "            w_in = float(np.prod(s_i, dtype=np.float64) ** (1.0 / len(s_i)))\n",
    "        else:\n",
    "            raise ValueError(\"gate must be 'prod'|'mean'|'geom'\")\n",
    "\n",
    "        # ----- core quadratic costs -----\n",
    "        err_quad = np.sum(Q_diag * (e_scaled ** 2))\n",
    "        err_eff = (1.0 - w_in) * err_quad + w_in * (lam_in * err_quad)\n",
    "        move = np.sum(R_diag * (du_scaled ** 2))\n",
    "\n",
    "        # ----- linear penalties around band edge -----\n",
    "        slope_at_edge = 2.0 * Q_diag * band_scaled\n",
    "\n",
    "        overflow = np.maximum(abs_e - band_scaled, 0.0)\n",
    "        lin_out = (1.0 - w_in) * np.sum(gamma_out * slope_at_edge * overflow)\n",
    "\n",
    "        inside_mag = np.minimum(abs_e, band_scaled)\n",
    "        lin_in = w_in * np.sum(gamma_in * slope_at_edge * inside_mag)\n",
    "\n",
    "        # ----- bonus near zero error -----\n",
    "        qb2 = Q_diag * (band_scaled ** 2)\n",
    "        z = abs_e / np.maximum(band_scaled, 1e-12)\n",
    "        phi = _phi(z)\n",
    "        bonus = w_in * beta * np.sum(qb2 * phi)\n",
    "\n",
    "        # ----- total reward -----\n",
    "        return (-(err_eff + move + lin_out + lin_in) + bonus)*0.01\n",
    "\n",
    "    params = dict(\n",
    "        k_rel=k_rel,\n",
    "        band_floor_phys=band_floor_phys,\n",
    "        band_floor_scaled=band_floor_scaled,\n",
    "        Q_diag=Q_diag,\n",
    "        R_diag=R_diag,\n",
    "        tau_frac=tau_frac,\n",
    "        gamma_out=gamma_out,\n",
    "        gamma_in=gamma_in,\n",
    "        beta=beta,\n",
    "        gate=gate,\n",
    "        lam_in=lam_in,\n",
    "        bonus_kind=bonus_kind,\n",
    "        bonus_k=bonus_k,\n",
    "        bonus_p=bonus_p,\n",
    "        bonus_c=bonus_c,\n",
    "    )\n",
    "    return params, reward_fn\n",
    "\n",
    "\n",
    "## Reward configuration\n",
    "n_inputs = 2\n",
    "\n",
    "dy = data_max[n_inputs:] - data_min[n_inputs:]\n",
    "y_sp_nom = 0.5 * (data_min[n_inputs:] + data_max[n_inputs:])\n",
    "\n",
    "k_rel = np.array([0.003, 0.0003])\n",
    "band_floor_phys = np.array([0.006, 0.07])\n",
    "\n",
    "band_phys = np.maximum(k_rel * np.abs(y_sp_nom), band_floor_phys)\n",
    "\n",
    "scale_factor = 1.0  # use 2.0 for [-1, 1] scaling, 1.0 for [0, 1]\n",
    "band_scaled = scale_factor * band_phys / dy\n",
    "\n",
    "q0 = 1.4\n",
    "Q_diag = q0 / np.maximum(band_scaled ** 2, 1e-12)\n",
    "\n",
    "print(\"dy:\", dy)\n",
    "print(\"y_sp_nom:\", y_sp_nom)\n",
    "print(\"band_phys:\", band_phys)\n",
    "print(\"band_scaled:\", band_scaled)\n",
    "print(\"Q_diag:\", Q_diag)\n",
    "Q_diag = np.array([518., 90.])  # rounded from the band-based calculation\n",
    "R_diag = np.array([90., 90.])  # move cost for du_scaled ~ 0.02\n",
    "\n",
    "n_inputs = 2\n",
    "\n",
    "print(\"Band scaled are:\")\n",
    "\n",
    "params, reward_fn = make_reward_fn_relative_QR(\n",
    "    data_min, data_max, n_inputs,\n",
    "    k_rel, band_floor_phys,\n",
    "    Q_diag, R_diag,\n",
    "    tau_frac=0.7,\n",
    "    gamma_out=0.5, gamma_in=0.5,\n",
    "    beta=7.0, gate=\"geom\", lam_in=1.0,\n",
    "    bonus_kind=\"exp\", bonus_k=12.0, bonus_p=0.6, bonus_c=20.0,\n",
    ")\n",
    "print(params)"
   ],
   "id": "1614d0131023c52f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy: [0.22165278 0.78153727]\n",
      "y_sp_nom: [  3.83915067 323.21371982]\n",
      "band_phys: [0.01151745 0.09696412]\n",
      "band_scaled: [0.05196169 0.12406845]\n",
      "Q_diag: [518.51529284  90.95055189]\n",
      "Band scaled are:\n",
      "{'k_rel': array([0.003 , 0.0003]), 'band_floor_phys': array([0.006, 0.07 ]), 'band_floor_scaled': array([0.02706937, 0.08956707]), 'Q_diag': array([518.,  90.]), 'R_diag': array([90., 90.]), 'tau_frac': 0.7, 'gamma_out': 0.5, 'gamma_in': 0.5, 'beta': 7.0, 'gate': 'geom', 'lam_in': 1.0, 'bonus_kind': 'exp', 'bonus_k': 12.0, 'bonus_p': 0.6, 'bonus_c': 20.0}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:15:29.936885Z",
     "start_time": "2026-01-08T04:15:29.922726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_reward_fn_relative_QR(\n",
    "        data_min, data_max, n_inputs,\n",
    "        k_rel, band_floor_phys,\n",
    "        Q_diag, R_diag,\n",
    "        tau_frac=0.7,\n",
    "        gamma_out=0.5, gamma_in=0.5,\n",
    "        beta=5.0, gate=\"geom\", lam_in=1.0,\n",
    "        bonus_kind=\"exp\", bonus_k=12.0, bonus_p=0.6, bonus_c=20.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reward with relative tracking bands.\n",
    "\n",
    "    data_min, data_max : arrays for [u_min..., y_min...], [u_max..., y_max...]\n",
    "    n_inputs           : number of inputs (so outputs start at index n_inputs)\n",
    "    k_rel              : per-output relative tolerance factors (same length as outputs)\n",
    "    band_floor_phys    : per-output minimum band in physical units\n",
    "    Q_diag, R_diag     : quadratic weights (same as before)\n",
    "    \"\"\"\n",
    "\n",
    "    data_min = np.asarray(data_min, float)\n",
    "    data_max = np.asarray(data_max, float)\n",
    "    dy = np.maximum(data_max[n_inputs:] - data_min[n_inputs:], 1e-12)  # phys range for each y\n",
    "\n",
    "    k_rel = np.asarray(k_rel, float)\n",
    "    band_floor_phys = np.asarray(band_floor_phys, float)\n",
    "    Q_diag = np.asarray(Q_diag, float)\n",
    "    R_diag = np.asarray(R_diag, float)\n",
    "\n",
    "    # floor in *scaled* coordinates (used if y_sp_phys is not provided)\n",
    "    band_floor_scaled = band_floor_phys / np.maximum(dy, 1e-12)\n",
    "\n",
    "    def _sigmoid(x):\n",
    "        x = np.clip(x, -60.0, 60.0)\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    def _phi(z, kind=bonus_kind, k=bonus_k, p=bonus_p, c=bonus_c):\n",
    "        z = np.clip(z, 0.0, 1.0)\n",
    "        if kind == \"linear\":\n",
    "            return 1.0 - z\n",
    "        if kind == \"quadratic\":\n",
    "            return (1.0 - z) ** 2\n",
    "        if kind == \"exp\":\n",
    "            return (np.exp(-k * z) - np.exp(-k)) / (1.0 - np.exp(-k))\n",
    "        if kind == \"power\":\n",
    "            return 1.0 - np.power(z, p)\n",
    "        if kind == \"log\":\n",
    "            return np.log1p(c * (1.0 - z)) / np.log1p(c)\n",
    "        raise ValueError(\"unknown bonus kind\")\n",
    "\n",
    "    def reward_fn(e_scaled, du_scaled, y_sp_phys=None):\n",
    "        \"\"\"\n",
    "        e_scaled : output error in scaled deviation space  (same as before)\n",
    "        du_scaled: input move in scaled deviation space    (same as before)\n",
    "        y_sp_phys: current setpoint in *physical* units (array len = n_outputs)\n",
    "        \"\"\"\n",
    "\n",
    "        e_scaled = np.asarray(e_scaled, float)\n",
    "        du_scaled = np.asarray(du_scaled, float)\n",
    "\n",
    "        # ----- dynamic band based on setpoint -----\n",
    "        if y_sp_phys is None:\n",
    "            # fallback: just use the floor\n",
    "            band_scaled = band_floor_scaled\n",
    "        else:\n",
    "            y_sp_phys_arr = np.asarray(y_sp_phys, float)\n",
    "            # band_phys_i = max(k_rel_i * |y_sp_i|, band_floor_phys_i)\n",
    "            band_phys = np.maximum(k_rel * np.abs(y_sp_phys_arr), band_floor_phys)\n",
    "            band_scaled = band_phys / np.maximum(dy, 1e-12)\n",
    "\n",
    "        tau_scaled = tau_frac * band_scaled\n",
    "\n",
    "        # ----- inside/outside gate -----\n",
    "        abs_e = np.abs(e_scaled)\n",
    "        s_i = _sigmoid((band_scaled - abs_e) / np.maximum(tau_scaled, 1e-12))\n",
    "\n",
    "        if gate == \"prod\":\n",
    "            w_in = float(np.prod(s_i, dtype=np.float64))\n",
    "        elif gate == \"mean\":\n",
    "            w_in = float(np.mean(s_i))\n",
    "        elif gate == \"geom\":\n",
    "            w_in = float(np.prod(s_i, dtype=np.float64) ** (1.0 / len(s_i)))\n",
    "        else:\n",
    "            raise ValueError(\"gate must be 'prod'|'mean'|'geom'\")\n",
    "\n",
    "        # ----- core quadratic costs -----\n",
    "        err_quad = np.sum(Q_diag * (e_scaled ** 2))\n",
    "        err_eff = (1.0 - w_in) * err_quad + w_in * (lam_in * err_quad)\n",
    "        move = np.sum(R_diag * (du_scaled ** 2))\n",
    "\n",
    "        # ----- linear penalties around band edge -----\n",
    "        slope_at_edge = 2.0 * Q_diag * band_scaled\n",
    "\n",
    "        overflow = np.maximum(abs_e - band_scaled, 0.0)\n",
    "        lin_out = (1.0 - w_in) * np.sum(gamma_out * slope_at_edge * overflow)\n",
    "\n",
    "        inside_mag = np.minimum(abs_e, band_scaled)\n",
    "        lin_in = w_in * np.sum(gamma_in * slope_at_edge * inside_mag)\n",
    "\n",
    "        # ----- bonus near zero error -----\n",
    "        qb2 = Q_diag * (band_scaled ** 2)\n",
    "        z = abs_e / np.maximum(band_scaled, 1e-12)\n",
    "        phi = _phi(z)\n",
    "        bonus = w_in * beta * np.sum(qb2 * phi)\n",
    "\n",
    "        # ----- total reward -----\n",
    "        return -(err_eff + move)\n",
    "\n",
    "    params = dict(\n",
    "        k_rel=k_rel,\n",
    "        band_floor_phys=band_floor_phys,\n",
    "        band_floor_scaled=band_floor_scaled,\n",
    "        Q_diag=Q_diag,\n",
    "        R_diag=R_diag,\n",
    "        tau_frac=tau_frac,\n",
    "        gamma_out=gamma_out,\n",
    "        gamma_in=gamma_in,\n",
    "        beta=beta,\n",
    "        gate=gate,\n",
    "        lam_in=lam_in,\n",
    "        bonus_kind=bonus_kind,\n",
    "        bonus_k=bonus_k,\n",
    "        bonus_p=bonus_p,\n",
    "        bonus_c=bonus_c,\n",
    "    )\n",
    "    return params, reward_fn\n",
    "\n",
    "\n",
    "## Reward configuration\n",
    "n_inputs = 2\n",
    "\n",
    "dy = data_max[n_inputs:] - data_min[n_inputs:]\n",
    "y_sp_nom = 0.5 * (data_min[n_inputs:] + data_max[n_inputs:])\n",
    "\n",
    "k_rel = np.array([0.003, 0.0003])\n",
    "band_floor_phys = np.array([0.006, 0.07])\n",
    "\n",
    "band_phys = np.maximum(k_rel * np.abs(y_sp_nom), band_floor_phys)\n",
    "\n",
    "scale_factor = 1.0  # use 2.0 for [-1, 1] scaling, 1.0 for [0, 1]\n",
    "band_scaled = scale_factor * band_phys / dy\n",
    "\n",
    "q0 = 1.4\n",
    "Q_diag = q0 / np.maximum(band_scaled ** 2, 1e-12)\n",
    "\n",
    "print(\"dy:\", dy)\n",
    "print(\"y_sp_nom:\", y_sp_nom)\n",
    "print(\"band_phys:\", band_phys)\n",
    "print(\"band_scaled:\", band_scaled)\n",
    "print(\"Q_diag:\", Q_diag)\n",
    "Q_diag = np.array([5., 1.])  # rounded from the band-based calculation\n",
    "R_diag = np.array([1., 1.])  # move cost for du_scaled ~ 0.02\n",
    "\n",
    "n_inputs = 2\n",
    "\n",
    "print(\"Band scaled are:\")\n",
    "\n",
    "params, reward_fn_mpc = make_reward_fn_relative_QR(\n",
    "    data_min, data_max, n_inputs,\n",
    "    k_rel, band_floor_phys,\n",
    "    Q_diag, R_diag,\n",
    "    tau_frac=0.7,\n",
    "    gamma_out=0.5, gamma_in=0.5,\n",
    "    beta=7.0, gate=\"geom\", lam_in=1.0,\n",
    "    bonus_kind=\"exp\", bonus_k=12.0, bonus_p=0.6, bonus_c=20.0,\n",
    ")\n",
    "print(params)"
   ],
   "id": "5c3cd9831cae5dd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy: [0.22165278 0.78153727]\n",
      "y_sp_nom: [  3.83915067 323.21371982]\n",
      "band_phys: [0.01151745 0.09696412]\n",
      "band_scaled: [0.05196169 0.12406845]\n",
      "Q_diag: [518.51529284  90.95055189]\n",
      "Band scaled are:\n",
      "{'k_rel': array([0.003 , 0.0003]), 'band_floor_phys': array([0.006, 0.07 ]), 'band_floor_scaled': array([0.02706937, 0.08956707]), 'Q_diag': array([5., 1.]), 'R_diag': array([1., 1.]), 'tau_frac': 0.7, 'gamma_out': 0.5, 'gamma_in': 0.5, 'beta': 7.0, 'gate': 'geom', 'lam_in': 1.0, 'bonus_kind': 'exp', 'bonus_k': 12.0, 'bonus_p': 0.6, 'bonus_c': 20.0}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T05:06:28.156703Z",
     "start_time": "2026-01-08T05:06:27.585897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.helpers import apply_min_max, reverse_min_max\n",
    "\n",
    "\n",
    "class CompatUnpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module.startswith(\"numpy._core\"):\n",
    "            module = \"numpy.core\" + module[len(\"numpy._core\"):]\n",
    "        return super().find_class(module, name)\n",
    "\n",
    "\n",
    "def load_pkl(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return CompatUnpickler(f).load()\n",
    "\n",
    "\n",
    "def _paper_style(font=16, label=18, tick=16, lw=2.8):\n",
    "    mpl.rcParams.update({\n",
    "        \"font.size\": font,\n",
    "        \"axes.labelsize\": label,\n",
    "        \"axes.labelweight\": \"bold\",\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.linestyle\": \"--\",\n",
    "        \"grid.linewidth\": 0.8,\n",
    "        \"grid.alpha\": 0.35,\n",
    "        \"xtick.labelsize\": tick,\n",
    "        \"ytick.labelsize\": tick,\n",
    "        \"lines.linewidth\": lw\n",
    "    })\n",
    "\n",
    "\n",
    "def _as_ysp_steps(y_sp):\n",
    "    y_sp = np.asarray(y_sp, float)\n",
    "    if y_sp.ndim != 2:\n",
    "        raise ValueError(\"y_sp must be 2D.\")\n",
    "    if y_sp.shape[0] < y_sp.shape[1]:\n",
    "        return y_sp.T\n",
    "    return y_sp\n",
    "\n",
    "\n",
    "def y_sp_phys_from_rl(rl_dict, n_inputs=2, align=\"tail\", n_steps=None):\n",
    "    y_sp_dev_scaled_all = _as_ysp_steps(rl_dict[\"y_sp\"])\n",
    "    data_min = np.asarray(rl_dict[\"data_min\"], float)\n",
    "    data_max = np.asarray(rl_dict[\"data_max\"], float)\n",
    "\n",
    "    y_ss_scaled = apply_min_max(np.asarray(rl_dict[\"steady_states\"][\"y_ss\"], float),\n",
    "                                data_min[n_inputs:], data_max[n_inputs:])\n",
    "\n",
    "    if n_steps is None:\n",
    "        y_sp_dev_scaled = y_sp_dev_scaled_all\n",
    "    else:\n",
    "        n_steps = int(n_steps)\n",
    "        if align == \"tail\":\n",
    "            y_sp_dev_scaled = y_sp_dev_scaled_all[-n_steps:, :]\n",
    "        elif align == \"head\":\n",
    "            y_sp_dev_scaled = y_sp_dev_scaled_all[:n_steps, :]\n",
    "        else:\n",
    "            raise ValueError(\"align must be 'tail' or 'head'.\")\n",
    "\n",
    "    y_sp_abs_scaled = y_sp_dev_scaled + y_ss_scaled\n",
    "    y_sp_phys = reverse_min_max(y_sp_abs_scaled, data_min[n_inputs:], data_max[n_inputs:])\n",
    "    return np.asarray(y_sp_phys, float)\n",
    "\n",
    "\n",
    "def step_rewards_from_yu(y_phys_full, u_phys, rl_meta, reward_fn, n_inputs=2, align=\"tail\"):\n",
    "    data_min = np.asarray(rl_meta[\"data_min\"], float)\n",
    "    data_max = np.asarray(rl_meta[\"data_max\"], float)\n",
    "\n",
    "    y_sp_dev_scaled_all = _as_ysp_steps(rl_meta[\"y_sp\"])\n",
    "\n",
    "    y_phys_full = np.asarray(y_phys_full, float)\n",
    "    u_phys = np.asarray(u_phys, float)\n",
    "\n",
    "    if y_phys_full.shape[0] >= 2 and (y_phys_full.shape[0] == u_phys.shape[0] + 1):\n",
    "        y_phys_all = y_phys_full[1:, :]\n",
    "    else:\n",
    "        y_phys_all = y_phys_full\n",
    "\n",
    "    n_y = y_phys_all.shape[0]\n",
    "    n_u = u_phys.shape[0]\n",
    "    n_sp = y_sp_dev_scaled_all.shape[0]\n",
    "    n_steps = int(min(n_y, n_u, n_sp))\n",
    "    if n_steps <= 0:\n",
    "        raise ValueError(\"Could not align lengths for reward recomputation.\")\n",
    "\n",
    "    if align == \"tail\":\n",
    "        y_phys = y_phys_all[-n_steps:, :]\n",
    "        u_use = u_phys[-n_steps:, :]\n",
    "        y_sp_dev_scaled = y_sp_dev_scaled_all[-n_steps:, :]\n",
    "    elif align == \"head\":\n",
    "        y_phys = y_phys_all[:n_steps, :]\n",
    "        u_use = u_phys[:n_steps, :]\n",
    "        y_sp_dev_scaled = y_sp_dev_scaled_all[:n_steps, :]\n",
    "    else:\n",
    "        raise ValueError(\"align must be 'tail' or 'head'.\")\n",
    "\n",
    "    y_scaled = apply_min_max(y_phys, data_min[n_inputs:], data_max[n_inputs:])\n",
    "    u_scaled = apply_min_max(u_use, data_min[:n_inputs], data_max[:n_inputs])\n",
    "\n",
    "    y_ss_scaled = apply_min_max(np.asarray(rl_meta[\"steady_states\"][\"y_ss\"], float),\n",
    "                                data_min[n_inputs:], data_max[n_inputs:])\n",
    "    y_sp_scaled = y_sp_dev_scaled + y_ss_scaled\n",
    "\n",
    "    e_scaled = y_scaled - y_sp_scaled\n",
    "\n",
    "    du_scaled = np.zeros_like(u_scaled)\n",
    "    du_scaled[1:, :] = u_scaled[1:, :] - u_scaled[:-1, :]\n",
    "\n",
    "    y_sp_phys = reverse_min_max(y_sp_scaled, data_min[n_inputs:], data_max[n_inputs:])\n",
    "\n",
    "    r = np.zeros(n_steps, dtype=float)\n",
    "    for t in range(n_steps):\n",
    "        r[t] = float(reward_fn(e_scaled[t], du_scaled[t], y_sp_phys=y_sp_phys[t]))\n",
    "    return r\n",
    "\n",
    "\n",
    "def episode_avg_from_steps(r_step, ep_len):\n",
    "    r_step = np.asarray(r_step, float).ravel()\n",
    "    ep_len = int(ep_len)\n",
    "    n_eps = int(len(r_step) // ep_len)\n",
    "    out = []\n",
    "    for e in range(n_eps):\n",
    "        a = e * ep_len\n",
    "        b = (e + 1) * ep_len\n",
    "        out.append(float(np.mean(r_step[a:b])))\n",
    "    return np.asarray(out, float)\n",
    "\n",
    "\n",
    "def _stack_1d(curves):\n",
    "    T = int(max(len(c) for c in curves))\n",
    "    X = np.full((len(curves), T), np.nan, dtype=float)\n",
    "    for i, c in enumerate(curves):\n",
    "        c = np.asarray(c, float).ravel()\n",
    "        X[i, :len(c)] = c\n",
    "    return X\n",
    "\n",
    "\n",
    "def _band_stats(X, band=\"minmax\"):\n",
    "    mu = np.nanmean(X, axis=0)\n",
    "    if band == \"minmax\":\n",
    "        lo = np.nanmin(X, axis=0)\n",
    "        hi = np.nanmax(X, axis=0)\n",
    "        return mu, lo, hi\n",
    "    if band == \"p25p75\":\n",
    "        lo = np.nanpercentile(X, 25, axis=0)\n",
    "        hi = np.nanpercentile(X, 75, axis=0)\n",
    "        return mu, lo, hi\n",
    "    raise ValueError(\"band must be 'minmax' or 'p25p75'.\")\n",
    "\n",
    "\n",
    "def _tail_last_episode(y_full, ep_len):\n",
    "    y_full = np.asarray(y_full, float)\n",
    "    ep_len = int(ep_len)\n",
    "    if y_full.shape[0] >= ep_len + 1:\n",
    "        return y_full[-(ep_len + 1):, :]\n",
    "    return y_full\n",
    "\n",
    "\n",
    "def _tail_last_episode_sp(y_sp_steps, ep_len):\n",
    "    y_sp_steps = np.asarray(y_sp_steps, float)\n",
    "    ep_len = int(ep_len)\n",
    "    if y_sp_steps.shape[0] >= ep_len:\n",
    "        return y_sp_steps[-ep_len:, :]\n",
    "    return y_sp_steps\n",
    "\n",
    "\n",
    "def plot_band_case_with_mpc(\n",
    "    rl_input_pkls,\n",
    "    mpc_results_pkl,\n",
    "    reward_fn,\n",
    "    out_dir,\n",
    "    mode=\"auto\",\n",
    "    band=\"minmax\",\n",
    "    n_inputs=2,\n",
    "    ylabels=(r\"$\\eta$ (L/g)\", r\"$T$ (K)\"),\n",
    "    start_episode=1\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    _paper_style()\n",
    "\n",
    "    C_RL = \"tab:blue\"\n",
    "    C_MPC = \"tab:green\"\n",
    "    C_SP = \"tab:red\"\n",
    "    LW = mpl.rcParams[\"lines.linewidth\"]\n",
    "    A_BAND = 0.22\n",
    "\n",
    "    rl_runs = [load_pkl(p) for p in rl_input_pkls]\n",
    "    rl0 = rl_runs[0]\n",
    "\n",
    "    ep_len = int(rl0[\"time_in_sub_episodes\"])\n",
    "    delta_t = float(rl0[\"delta_t\"])\n",
    "\n",
    "    rl_reward_curves = [np.asarray(d[\"avg_rewards\"], float).ravel() for d in rl_runs]\n",
    "    Xr = _stack_1d(rl_reward_curves)\n",
    "    mu_r, lo_r, hi_r = _band_stats(Xr, band=band)\n",
    "\n",
    "    start_episode = int(max(1, start_episode))\n",
    "    i0 = start_episode - 1\n",
    "    if i0 >= len(mu_r):\n",
    "        i0 = 0\n",
    "\n",
    "    mu_r = mu_r[i0:]\n",
    "    lo_r = lo_r[i0:]\n",
    "    hi_r = hi_r[i0:]\n",
    "    xep = np.arange(start_episode, start_episode + len(mu_r))\n",
    "\n",
    "    mpc = load_pkl(mpc_results_pkl)\n",
    "    y_mpc = np.asarray(mpc[\"y_mpc\"], float)\n",
    "    u_mpc = np.asarray(mpc[\"u_mpc\"], float)\n",
    "\n",
    "    r_step_mpc = step_rewards_from_yu(y_mpc, u_mpc, rl0, reward_fn, n_inputs=n_inputs, align=\"tail\")\n",
    "    r_ep_mpc = episode_avg_from_steps(r_step_mpc, ep_len=ep_len)\n",
    "\n",
    "    if mode == \"auto\":\n",
    "        if len(r_ep_mpc) <= 2 and len(mu_r) > len(r_ep_mpc):\n",
    "            mode_use = \"nominal\"\n",
    "        else:\n",
    "            mode_use = \"disturbance\"\n",
    "    else:\n",
    "        mode_use = mode\n",
    "\n",
    "    plt.figure(figsize=(7.6, 4.8))\n",
    "    plt.plot(xep, mu_r, \"-\", color=C_RL, lw=LW)\n",
    "    plt.fill_between(xep, lo_r, hi_r, color=C_RL, alpha=A_BAND)\n",
    "\n",
    "    if mode_use == \"nominal\":\n",
    "        mpc_const = float(r_ep_mpc[-1]) if len(r_ep_mpc) else np.nan\n",
    "        plt.hlines(mpc_const, xmin=xep[0], xmax=xep[-1], color=C_MPC, linestyle=\"--\", lw=LW)\n",
    "    else:\n",
    "        r_mpc_plot = r_ep_mpc[i0:i0 + len(mu_r)]\n",
    "        n = min(len(xep), len(r_mpc_plot))\n",
    "        plt.plot(xep[:n], r_mpc_plot[:n], \"--\", color=C_MPC, lw=LW)\n",
    "\n",
    "    plt.xlabel(\"Episode #\")\n",
    "    plt.ylabel(\"Avg. reward\")\n",
    "    plt.ylim((-30, 0.5))\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.xaxis.set_major_locator(mtick.MaxNLocator(8, integer=True))\n",
    "    ax.xaxis.set_minor_locator(mtick.AutoMinorLocator(2))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"fig_reward_band_mpc_{mode_use}.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    rl_y_last = []\n",
    "    for d in rl_runs:\n",
    "        y = np.asarray(d.get(\"y_rl\", d.get(\"y_mpc\")), float)\n",
    "        rl_y_last.append(_tail_last_episode(y, ep_len))\n",
    "\n",
    "    y_sp_phys = y_sp_phys_from_rl(rl0, n_inputs=n_inputs, align=\"tail\")\n",
    "    y_sp_last = _tail_last_episode_sp(y_sp_phys, ep_len)\n",
    "    y_mpc_last = _tail_last_episode(y_mpc, ep_len)\n",
    "\n",
    "    W = min(ep_len, y_sp_last.shape[0])\n",
    "    t_line = np.linspace(0.0, W * delta_t, W + 1)\n",
    "    t_step = t_line[:-1]\n",
    "\n",
    "    Y0 = []\n",
    "    Y1 = []\n",
    "    for y in rl_y_last:\n",
    "        if y.shape[0] >= W + 1:\n",
    "            y = y[-(W + 1):, :]\n",
    "        else:\n",
    "            pad = (W + 1) - y.shape[0]\n",
    "            y = np.vstack([np.full((pad, y.shape[1]), np.nan), y])\n",
    "        Y0.append(y[:, 0])\n",
    "        Y1.append(y[:, 1])\n",
    "\n",
    "    X0 = _stack_1d(Y0)\n",
    "    X1 = _stack_1d(Y1)\n",
    "    mu0, lo0, hi0 = _band_stats(X0, band=band)\n",
    "    mu1, lo1, hi1 = _band_stats(X1, band=band)\n",
    "\n",
    "    if y_mpc_last.shape[0] >= W + 1:\n",
    "        y_mpc_last = y_mpc_last[-(W + 1):, :]\n",
    "    else:\n",
    "        pad = (W + 1) - y_mpc_last.shape[0]\n",
    "        y_mpc_last = np.vstack([np.full((pad, y_mpc_last.shape[1]), np.nan), y_mpc_last])\n",
    "\n",
    "    plt.figure(figsize=(7.8, 5.8))\n",
    "\n",
    "    ax = plt.subplot(2, 1, 1)\n",
    "    ax.plot(t_line, mu0[:W + 1], \"-\", color=C_RL, lw=LW, zorder=2)\n",
    "    ax.fill_between(t_line, lo0[:W + 1], hi0[:W + 1], color=C_RL, alpha=A_BAND, zorder=1)\n",
    "    ax.plot(t_line, y_mpc_last[:W + 1, 0], \"--\", color=C_MPC, lw=LW, zorder=2)\n",
    "    ax.step(t_step, y_sp_last[-W:, 0], where=\"post\", linestyle=\"--\", color=C_SP, lw=LW, zorder=3)\n",
    "    ax.set_ylabel(ylabels[0])\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.xaxis.set_major_locator(mtick.MaxNLocator(6))\n",
    "    ax.xaxis.set_minor_locator(mtick.AutoMinorLocator(2))\n",
    "    ax.xaxis.set_major_formatter(mtick.FormatStrFormatter(\"%.1f\"))\n",
    "\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    ax.plot(t_line, mu1[:W + 1], \"-\", color=C_RL, lw=LW, zorder=2)\n",
    "    ax.fill_between(t_line, lo1[:W + 1], hi1[:W + 1], color=C_RL, alpha=A_BAND, zorder=1)\n",
    "    ax.plot(t_line, y_mpc_last[:W + 1, 1], \"--\", color=C_MPC, lw=LW, zorder=2)\n",
    "    ax.step(t_step, y_sp_last[-W:, 1], where=\"post\", linestyle=\"--\", color=C_SP, lw=LW, zorder=3)\n",
    "    ax.set_ylabel(ylabels[1])\n",
    "    ax.set_xlabel(\"Time (h)\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.xaxis.set_major_locator(mtick.MaxNLocator(6))\n",
    "    ax.xaxis.set_minor_locator(mtick.AutoMinorLocator(2))\n",
    "    ax.xaxis.set_major_formatter(mtick.FormatStrFormatter(\"%.1f\"))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"fig_last_episode_outputs_band_mpc_{mode_use}.png\"),\n",
    "                dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "def _get_eval_abs_error_scaled(rl_dict, n_inputs=2, eval_len=800, sub_len=400, settle_len=80):\n",
    "    data_min = np.asarray(rl_dict[\"data_min\"], float)\n",
    "    data_max = np.asarray(rl_dict[\"data_max\"], float)\n",
    "\n",
    "    y_full = np.asarray(rl_dict.get(\"y_rl\", rl_dict.get(\"y_mpc\")), float)\n",
    "    if y_full.shape[0] >= 2 and \"u_mpc\" in rl_dict and (y_full.shape[0] == np.asarray(rl_dict[\"u_mpc\"]).shape[0] + 1):\n",
    "        y_steps = y_full[1:, :]\n",
    "    else:\n",
    "        y_steps = y_full\n",
    "\n",
    "    y_sp_dev_scaled_all = _as_ysp_steps(rl_dict[\"y_sp\"])\n",
    "\n",
    "    n_steps = int(min(y_steps.shape[0], y_sp_dev_scaled_all.shape[0]))\n",
    "    y_steps = y_steps[-n_steps:, :]\n",
    "    y_sp_dev_scaled_all = y_sp_dev_scaled_all[-n_steps:, :]\n",
    "\n",
    "    eval_len = int(min(eval_len, n_steps))\n",
    "    y_eval = y_steps[-eval_len:, :]\n",
    "    y_sp_dev_eval = y_sp_dev_scaled_all[-eval_len:, :]\n",
    "\n",
    "    y_scaled = apply_min_max(y_eval, data_min[n_inputs:], data_max[n_inputs:])\n",
    "    y_ss_scaled = apply_min_max(np.asarray(rl_dict[\"steady_states\"][\"y_ss\"], float),\n",
    "                                data_min[n_inputs:], data_max[n_inputs:])\n",
    "    y_sp_scaled = y_sp_dev_eval + y_ss_scaled\n",
    "\n",
    "    e_scaled = y_scaled - y_sp_scaled\n",
    "    e_abs = np.abs(e_scaled)\n",
    "\n",
    "    sub_len = int(min(sub_len, eval_len // 2))\n",
    "    settle_len = int(min(settle_len, sub_len))\n",
    "\n",
    "    a = e_abs[:sub_len, :]\n",
    "    b = e_abs[sub_len:sub_len + sub_len, :]\n",
    "\n",
    "    a_ss = a[-settle_len:, :]\n",
    "    b_ss = b[-settle_len:, :]\n",
    "    return a_ss, b_ss\n",
    "\n",
    "\n",
    "def boxplot_abs_error_scaled_last_eval_two_rl(\n",
    "    rl1_pkls,\n",
    "    rl2_pkls,\n",
    "    out_dir,\n",
    "    n_inputs=2,\n",
    "    eval_len=800,\n",
    "    sub_len=400,\n",
    "    settle_len=80,\n",
    "    ylabels=(r\"$\\eta$\", r\"$T$\")\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    _paper_style()\n",
    "\n",
    "    rl1 = [load_pkl(p) for p in rl1_pkls]\n",
    "    rl2 = [load_pkl(p) for p in rl2_pkls]\n",
    "\n",
    "    def collect(runs):\n",
    "        sp_a = []\n",
    "        sp_b = []\n",
    "        for d in runs:\n",
    "            a_ss, b_ss = _get_eval_abs_error_scaled(\n",
    "                d,\n",
    "                n_inputs=n_inputs,\n",
    "                eval_len=eval_len,\n",
    "                sub_len=sub_len,\n",
    "                settle_len=settle_len\n",
    "            )\n",
    "            sp_a.append(a_ss)\n",
    "            sp_b.append(b_ss)\n",
    "        sp_a = np.concatenate(sp_a, axis=0)\n",
    "        sp_b = np.concatenate(sp_b, axis=0)\n",
    "        return sp_a, sp_b\n",
    "\n",
    "    a1, b1 = collect(rl1)\n",
    "    a2, b2 = collect(rl2)\n",
    "\n",
    "    groups = [\n",
    "        (a1[:, 0], a2[:, 0], f\"SP(a)\\n{ylabels[0]}\"),\n",
    "        (b1[:, 0], b2[:, 0], f\"SP(b)\\n{ylabels[0]}\"),\n",
    "        (a1[:, 1], a2[:, 1], f\"SP(a)\\n{ylabels[1]}\"),\n",
    "        (b1[:, 1], b2[:, 1], f\"SP(b)\\n{ylabels[1]}\")\n",
    "    ]\n",
    "\n",
    "    data = []\n",
    "    positions = []\n",
    "    centers = np.arange(1, len(groups) + 1, dtype=float)\n",
    "    dx = 0.18\n",
    "\n",
    "    for i, (d_rl1, d_rl2, _) in enumerate(groups):\n",
    "        c = centers[i]\n",
    "        data.append(np.asarray(d_rl1, float).ravel())\n",
    "        positions.append(c - dx)\n",
    "        data.append(np.asarray(d_rl2, float).ravel())\n",
    "        positions.append(c + dx)\n",
    "\n",
    "    plt.figure(figsize=(8.6, 4.9))\n",
    "    bp = plt.boxplot(\n",
    "        data,\n",
    "        positions=positions,\n",
    "        widths=0.28,\n",
    "        patch_artist=True,\n",
    "        showfliers=False,\n",
    "        whis=1.5\n",
    "    )\n",
    "\n",
    "    c_rl1 = \"#4C72B0\"  # muted blue\n",
    "    c_rl2 = \"#DD8452\"  # muted orange\n",
    "\n",
    "    for k, box in enumerate(bp[\"boxes\"]):\n",
    "        is_rl1 = (k % 2 == 0)  # ordering: RL1 then RL2 for each region\n",
    "        box.set_facecolor(c_rl1 if is_rl1 else c_rl2)\n",
    "        box.set_alpha(0.55)\n",
    "        box.set_edgecolor(\"black\")\n",
    "        box.set_linewidth(2.0)\n",
    "        box.set_hatch(None)  # remove hatch since we have color\n",
    "\n",
    "    for key in [\"whiskers\", \"caps\", \"medians\"]:\n",
    "        for line in bp[key]:\n",
    "            line.set_color(\"black\")\n",
    "            line.set_linewidth(2.0)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylabel(r\"$|e|$ (scaled)\")\n",
    "    ax.set_xticks(centers)\n",
    "    ax.set_xticklabels([g[2] for g in groups], rotation=0, ha=\"center\")\n",
    "\n",
    "    # separators between the 4 regions\n",
    "    for x in (centers[:-1] + centers[1:]) / 2.0:\n",
    "        ax.axvline(x, linestyle=\"--\", linewidth=1.2, alpha=0.35)\n",
    "\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.yaxis.set_major_locator(mtick.MaxNLocator(6))\n",
    "\n",
    "    # tighter margins, looks less \"spread out\"\n",
    "    ax.set_xlim(0.5, len(groups) + 0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(out_dir, \"fig_box_abs_error_scaled_eval_last.png\"),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "\n",
    "def ss_error_last_eval_phys_stats(\n",
    "    rl_pkls,\n",
    "    n_inputs=2,\n",
    "    eval_len=800,\n",
    "    sub_len=400,\n",
    "    settle_len=80\n",
    "):\n",
    "    runs = [load_pkl(p) for p in rl_pkls]\n",
    "    d0 = runs[0]\n",
    "\n",
    "    data_min = np.asarray(d0[\"data_min\"], float)\n",
    "    data_max = np.asarray(d0[\"data_max\"], float)\n",
    "\n",
    "    vals = []\n",
    "    for d in runs:\n",
    "        y_full = np.asarray(d.get(\"y_rl\", d.get(\"y_mpc\")), float)\n",
    "        if y_full.shape[0] >= 2 and \"u_mpc\" in d and (y_full.shape[0] == np.asarray(d[\"u_mpc\"]).shape[0] + 1):\n",
    "            y_steps = y_full[1:, :]\n",
    "        else:\n",
    "            y_steps = y_full\n",
    "\n",
    "        y_sp_phys_all = y_sp_phys_from_rl(d, n_inputs=n_inputs, align=\"tail\", n_steps=y_steps.shape[0])\n",
    "\n",
    "        n_steps = int(min(y_steps.shape[0], y_sp_phys_all.shape[0]))\n",
    "        y_steps = y_steps[-n_steps:, :]\n",
    "        y_sp_phys_all = y_sp_phys_all[-n_steps:, :]\n",
    "\n",
    "        eval_len_use = int(min(eval_len, n_steps))\n",
    "        y_eval = y_steps[-eval_len_use:, :]\n",
    "        sp_eval = y_sp_phys_all[-eval_len_use:, :]\n",
    "\n",
    "        sub_len_use = int(min(sub_len, eval_len_use // 2))\n",
    "        settle_len_use = int(min(settle_len, sub_len_use))\n",
    "\n",
    "        ya = y_eval[:sub_len_use, :]\n",
    "        yb = y_eval[sub_len_use:sub_len_use + sub_len_use, :]\n",
    "        spa = sp_eval[:sub_len_use, :]\n",
    "        spb = sp_eval[sub_len_use:sub_len_use + sub_len_use, :]\n",
    "\n",
    "        ea = np.abs(ya - spa)[-settle_len_use:, :]\n",
    "        eb = np.abs(yb - spb)[-settle_len_use:, :]\n",
    "\n",
    "        vals.append([np.mean(ea, axis=0), np.mean(eb, axis=0)])\n",
    "\n",
    "    vals = np.asarray(vals, float)  # (n_runs, 2 SP, 2 out)\n",
    "    mu = np.mean(vals, axis=0)\n",
    "    sd = np.std(vals, axis=0, ddof=1) if vals.shape[0] > 1 else np.zeros_like(mu)\n",
    "    return mu, sd\n",
    "\n",
    "\n",
    "def print_table_block(mu1, sd1, mu2, sd2, name_out=(\"eta\", \"T\")):\n",
    "    # mu shape (2 SP, 2 out) -> [SP(a), SP(b)] x [eta, T]\n",
    "    # print as: output rows: RL1, RL2, Reduction\n",
    "    for j, nm in enumerate(name_out):\n",
    "        a1 = mu1[0, j]\n",
    "        b1 = mu1[1, j]\n",
    "        a2 = mu2[0, j]\n",
    "        b2 = mu2[1, j]\n",
    "        r_a = 100.0 * (1.0 - a2 / max(a1, 1e-12))\n",
    "        r_b = 100.0 * (1.0 - b2 / max(b1, 1e-12))\n",
    "\n",
    "        sa1 = sd1[0, j]\n",
    "        sb1 = sd1[1, j]\n",
    "        sa2 = sd2[0, j]\n",
    "        sb2 = sd2[1, j]\n",
    "\n",
    "        print(f\"{nm}:\")\n",
    "        print(f\"  RL1 mean: SP(a)={a1:.3f}, SP(b)={b1:.3f}\")\n",
    "        print(f\"  RL1 std : SP(a)={sa1:.3f}, SP(b)={sb1:.3f}\")\n",
    "        print(f\"  RL2 mean: SP(a)={a2:.3f}, SP(b)={b2:.3f}\")\n",
    "        print(f\"  RL2 std : SP(a)={sa2:.3f}, SP(b)={sb2:.3f}\")\n",
    "        print(f\"  Reduction (%): SP(a)={r_a:.0f}, SP(b)={r_b:.0f}\")\n",
    "        print(\"\")\n",
    "def compare_three_paths_outputs_only_polymer(\n",
    "    rl1_path,\n",
    "    rl2_path,\n",
    "    mpc_path,\n",
    "    directory,\n",
    "    prefix_name,\n",
    "    start_idx=-800,\n",
    "    n_inputs=2,\n",
    "    ylabels=(r\"$\\eta$ (L/g)\", r\"$T$ (K)\"),\n",
    "    save_pdf=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare RL1 vs RL2 vs MPC for OUTPUTS ONLY on the tail window (default last 800 samples).\n",
    "\n",
    "    Assumes:\n",
    "      - y is stored as (N+1, n_out) or (N, n_out)\n",
    "      - setpoint y_sp is stored per-step (N, n_out) in scaled deviation space\n",
    "      - uses y_sp_phys_from_rl(...) from your polymer plotting helpers to reconstruct physical setpoints\n",
    "\n",
    "    Saves:\n",
    "      outputs_compare_three_polymer.png (+ .pdf if save_pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_first(d, keys):\n",
    "        for k in keys:\n",
    "            if k in d and d[k] is not None:\n",
    "                return d[k]\n",
    "        return None\n",
    "\n",
    "    def _mk_outdir(directory, prefix_name):\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        out_dir = os.path.join(directory, prefix_name, ts)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        return out_dir\n",
    "\n",
    "    def _save_fig(fig, out_dir, stem, save_pdf=True):\n",
    "        fig.savefig(os.path.join(out_dir, f\"{stem}.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "        if save_pdf:\n",
    "            fig.savefig(os.path.join(out_dir, f\"{stem}.pdf\"), bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    def _make_axes_bold(ax, spine_lw=2.0, tick_w=2.0):\n",
    "        for sp in ax.spines.values():\n",
    "            sp.set_linewidth(spine_lw)\n",
    "        ax.tick_params(axis=\"both\", width=tick_w)\n",
    "\n",
    "    def _slice_y_line(y, W):\n",
    "        \"\"\"\n",
    "        Return y_line with shape (W+1, n_out) from tail.\n",
    "        If y has only W points (step samples), prepend first sample to make W+1.\n",
    "        \"\"\"\n",
    "        y = np.asarray(y, float)\n",
    "        if y.ndim != 2:\n",
    "            raise ValueError(\"y must be 2D (time, n_out).\")\n",
    "\n",
    "        if y.shape[0] >= W + 1:\n",
    "            return y[-(W + 1):, :]\n",
    "\n",
    "        if y.shape[0] == W:\n",
    "            return np.vstack([y[:1, :], y])\n",
    "\n",
    "        # pad front if too short\n",
    "        pad = (W + 1) - y.shape[0]\n",
    "        return np.vstack([np.full((pad, y.shape[1]), np.nan), y])\n",
    "\n",
    "    # ---- load data ----\n",
    "    d1 = load_pkl(rl1_path)\n",
    "    d2 = load_pkl(rl2_path)\n",
    "    dm = load_pkl(mpc_path)\n",
    "\n",
    "    y1 = np.asarray(_get_first(d1, [\"y_rl\", \"y_mpc\", \"y\"]), float)\n",
    "    y2 = np.asarray(_get_first(d2, [\"y_rl\", \"y_mpc\", \"y\"]), float)\n",
    "    ym = np.asarray(_get_first(dm, [\"y_rl\", \"y_mpc\", \"y\"]), float)\n",
    "\n",
    "    if y1.ndim != 2 or y2.ndim != 2 or ym.ndim != 2:\n",
    "        raise ValueError(\"Could not read y trajectories. Expected 2D arrays.\")\n",
    "\n",
    "    n_out = int(y1.shape[1])\n",
    "    if len(ylabels) != n_out:\n",
    "        raise ValueError(\"ylabels length must match number of outputs in y.\")\n",
    "\n",
    "    delta_t = float(d1[\"delta_t\"])\n",
    "\n",
    "    # ---- choose tail window length W ----\n",
    "    if start_idx >= 0:\n",
    "        raise ValueError(\"This function currently expects start_idx < 0 (tail window), e.g., -800.\")\n",
    "\n",
    "    W_req = int(abs(start_idx))\n",
    "\n",
    "    # setpoint is per-step with length N_steps\n",
    "    sp_phys_all = y_sp_phys_from_rl(d1, n_inputs=n_inputs, align=\"tail\")\n",
    "    n_sp = int(sp_phys_all.shape[0])\n",
    "\n",
    "    # y may be (N+1, n_out) or (N, n_out). Convert to a consistent W+1 tail later.\n",
    "    # Max feasible W is limited by setpoint length and y lengths\n",
    "    # - if y is (N+1) points, its step-count is N\n",
    "    def _steps_available_from_y(y):\n",
    "        y = np.asarray(y, float)\n",
    "        if y.shape[0] >= 2:\n",
    "            return y.shape[0] - 1\n",
    "        return 0\n",
    "\n",
    "    W_max = min(\n",
    "        W_req,\n",
    "        n_sp,\n",
    "        _steps_available_from_y(y1),\n",
    "        _steps_available_from_y(y2),\n",
    "        _steps_available_from_y(ym),\n",
    "    )\n",
    "    if W_max <= 5:\n",
    "        raise ValueError(\"Tail window W is too small after alignment. Check your files and start_idx.\")\n",
    "\n",
    "    W = int(W_max)\n",
    "\n",
    "    # ---- build tail time + setpoint ----\n",
    "    sp_tail = sp_phys_all[-W:, :]  # (W, n_out)\n",
    "    t_line = np.linspace(0.0, W * delta_t, W + 1)\n",
    "    t_step = t_line[:-1]\n",
    "\n",
    "    # ---- slice y tails ----\n",
    "    y1_tail = _slice_y_line(y1, W)\n",
    "    y2_tail = _slice_y_line(y2, W)\n",
    "    ym_tail = _slice_y_line(ym, W)\n",
    "\n",
    "    # ---- style ----\n",
    "    _paper_style()  # your existing helper\n",
    "\n",
    "    c_rl1 = \"tab:blue\"\n",
    "    c_rl2 = \"tab:orange\"\n",
    "    c_mpc = \"tab:green\"\n",
    "    c_sp = \"tab:red\"\n",
    "\n",
    "    out_dir = _mk_outdir(directory, prefix_name)\n",
    "\n",
    "    # ---- plot ----\n",
    "    fig, axs = plt.subplots(n_out, 1, figsize=(8.2, 5.6), sharex=True)\n",
    "    if n_out == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for j in range(n_out):\n",
    "        ax = axs[j]\n",
    "        ax.plot(t_line, y1_tail[:, j], \"-\", color=c_rl1)\n",
    "        ax.plot(t_line, y2_tail[:, j], \"-\", color=c_rl2)\n",
    "        ax.plot(t_line, ym_tail[:, j], \"--\", color=c_mpc)\n",
    "        ax.step(t_step, sp_tail[:, j], where=\"post\", linestyle=\"--\", color=c_sp)\n",
    "\n",
    "        ax.set_ylabel(ylabels[j])\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        _make_axes_bold(ax)\n",
    "\n",
    "    axs[-1].set_xlabel(\"Time (h)\")\n",
    "\n",
    "    _save_fig(fig, out_dir, \"outputs_compare_three_polymer\", save_pdf=save_pdf)\n",
    "    return out_dir"
   ],
   "id": "cb3df092efeb1d61",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Nominal",
   "id": "ebe4525acb728c94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:51:56.316993Z",
     "start_time": "2026-01-08T04:51:56.313767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rl1_pkls = [\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal_mpc\\20260107_015906\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal_mpc\\20260107_040655\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal_mpc\\20260107_051048\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal_mpc\\20260107_071832\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal_mpc\\20260107_092639\\input_data.pkl\",\n",
    "]\n",
    "\n",
    "rl2_pkls = [\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal\\20260107_021207\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal\\20260107_032442\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal\\20260107_070316\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal\\20260107_081551\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal\\20260107_111718\\input_data.pkl\",\n",
    "]\n",
    "mpc_pkl = os.path.join(dir_path, \"mpc_results_nominal.pickle\")"
   ],
   "id": "bd4abc1c922343d9",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:19:13.443678Z",
     "start_time": "2026-01-08T04:19:12.753692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_dir = plot_band_case_with_mpc(\n",
    "    rl_input_pkls=rl1_pkls,\n",
    "    mpc_results_pkl=mpc_pkl,\n",
    "    reward_fn=reward_fn_mpc,\n",
    "    out_dir=os.path.join(dir_path, \"paper_plots_rl1_nominal\"),\n",
    "    mode=\"auto\",\n",
    "    band=\"minmax\",\n",
    "    ylabels=(r\"$\\eta$ (L/g)\", r\"$T$ (K)\"),\n",
    "    start_episode=5\n",
    ")\n",
    "print(out_dir)"
   ],
   "id": "b18175f86537d613",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\paper_plots_rl1_nominal\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:19:16.341798Z",
     "start_time": "2026-01-08T04:19:15.910213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_dir = plot_band_case_with_mpc(\n",
    "    rl_input_pkls=rl2_pkls,\n",
    "    mpc_results_pkl=mpc_pkl,\n",
    "    reward_fn=reward_fn,\n",
    "    out_dir=os.path.join(dir_path, \"paper_plots_rl2_nominal\"),\n",
    "    mode=\"auto\",\n",
    "    band=\"minmax\",\n",
    "    ylabels=(r\"$\\eta$ (L/g)\", r\"$T$ (K)\"),\n",
    "    start_episode=5\n",
    ")\n",
    "print(out_dir)"
   ],
   "id": "d478c0a6d9c3bee5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\paper_plots_rl2_nominal\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:19:16.645402Z",
     "start_time": "2026-01-08T04:19:16.380857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "boxplot_abs_error_scaled_last_eval_two_rl(\n",
    "    rl1_pkls=rl1_pkls,\n",
    "    rl2_pkls=rl2_pkls,\n",
    "    out_dir=os.path.join(dir_path, \"box_plots_nominal\"),\n",
    "    eval_len=800,\n",
    "    sub_len=400,\n",
    "    settle_len=10\n",
    ")"
   ],
   "id": "164bf035dccd5675",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HAMEDI\\\\OneDrive - McMaster University\\\\PythonProjects\\\\Polymer_example\\\\Data\\\\box_plots_nominal'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:19:16.841642Z",
     "start_time": "2026-01-08T04:19:16.682111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mu1, sd1 = ss_error_last_eval_phys_stats(rl1_pkls, eval_len=800, sub_len=400, settle_len=80)\n",
    "mu2, sd2 = ss_error_last_eval_phys_stats(rl2_pkls, eval_len=800, sub_len=400, settle_len=80)\n",
    "\n",
    "print_table_block(mu1, sd1, mu2, sd2, name_out=(\"eta\", \"T\"))"
   ],
   "id": "281547ea89a3a566",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta:\n",
      "  RL1 mean: SP(a)=0.034, SP(b)=0.026\n",
      "  RL1 std : SP(a)=0.024, SP(b)=0.020\n",
      "  RL2 mean: SP(a)=0.001, SP(b)=0.002\n",
      "  RL2 std : SP(a)=0.001, SP(b)=0.003\n",
      "  Reduction (%): SP(a)=98, SP(b)=90\n",
      "\n",
      "T:\n",
      "  RL1 mean: SP(a)=0.093, SP(b)=0.058\n",
      "  RL1 std : SP(a)=0.085, SP(b)=0.043\n",
      "  RL2 mean: SP(a)=0.008, SP(b)=0.009\n",
      "  RL2 std : SP(a)=0.009, SP(b)=0.005\n",
      "  Reduction (%): SP(a)=92, SP(b)=84\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:51:59.684972Z",
     "start_time": "2026-01-08T04:51:59.431813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_dir = compare_three_paths_outputs_only_polymer(\n",
    "    rl1_path=r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal_mpc\\20260107_051048\\input_data.pkl\",\n",
    "    rl2_path=r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_nominal\\20260107_070316\\input_data.pkl\",\n",
    "    mpc_path=mpc_pkl,\n",
    "    directory=dir_path,\n",
    "    prefix_name=\"three_way_compare_nominal\",\n",
    "    start_idx=-800,\n",
    "    ylabels=(r\"$\\eta$ (L/g)\", r\"$T$ (K)\"),\n",
    "    save_pdf=True\n",
    ")\n",
    "print(out_dir)"
   ],
   "id": "c0ba03ecbc056003",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\three_way_compare_nominal\\20260107_235159\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Disturb",
   "id": "597069c7f9e23bf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T05:06:32.198253Z",
     "start_time": "2026-01-08T05:06:32.195056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rl1_pkls = [\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist_mpc\\20260107_020146\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist_mpc\\20260107_030554\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist_mpc\\20260107_051341\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist_mpc\\20260107_072153\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist_mpc\\20260107_082549\\input_data.pkl\",\n",
    "]\n",
    "\n",
    "rl2_pkls = [\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist\\20260107_021502\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist\\20260107_044044\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist\\20260107_081911\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist\\20260107_093159\\input_data.pkl\",\n",
    "    r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist\\20260107_104200\\input_data.pkl\",\n",
    "]\n",
    "mpc_pkl = os.path.join(dir_path, \"mpc_results_dist.pickle\")"
   ],
   "id": "5800845697cd5435",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T05:06:43.038501Z",
     "start_time": "2026-01-08T05:06:37.602195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_dir = plot_band_case_with_mpc(\n",
    "    rl_input_pkls=rl1_pkls,\n",
    "    mpc_results_pkl=mpc_pkl,\n",
    "    reward_fn=reward_fn_mpc,\n",
    "    out_dir=os.path.join(dir_path, \"paper_plots_rl1_dist\"),\n",
    "    mode=\"auto\",\n",
    "    band=\"minmax\",\n",
    "    ylabels=(r\"$\\eta$ (L/g)\", r\"$T$ (K)\"),\n",
    "    start_episode=5\n",
    ")\n",
    "print(out_dir)"
   ],
   "id": "ef454160f0996672",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\paper_plots_rl1_dist\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:28:39.041623Z",
     "start_time": "2026-01-08T04:28:32.578131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_dir = plot_band_case_with_mpc(\n",
    "    rl_input_pkls=rl2_pkls,\n",
    "    mpc_results_pkl=mpc_pkl,\n",
    "    reward_fn=reward_fn,\n",
    "    out_dir=os.path.join(dir_path, \"paper_plots_rl2_dist\"),\n",
    "    mode=\"auto\",\n",
    "    band=\"minmax\",\n",
    "    ylabels=(r\"$\\eta$ (L/g)\", r\"$T$ (K)\"),\n",
    "    start_episode=5\n",
    ")\n",
    "print(out_dir)"
   ],
   "id": "7c5df324d2e17d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\paper_plots_rl2_dist\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:28:39.953721Z",
     "start_time": "2026-01-08T04:28:39.712917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "boxplot_abs_error_scaled_last_eval_two_rl(\n",
    "    rl1_pkls=rl1_pkls,\n",
    "    rl2_pkls=rl2_pkls,\n",
    "    out_dir=os.path.join(dir_path, \"box_plots_dist\"),\n",
    "    eval_len=800,\n",
    "    sub_len=400,\n",
    "    settle_len=10\n",
    ")"
   ],
   "id": "b25433ffab008a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HAMEDI\\\\OneDrive - McMaster University\\\\PythonProjects\\\\Polymer_example\\\\Data\\\\box_plots_dist'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:28:45.144955Z",
     "start_time": "2026-01-08T04:28:44.969984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mu1, sd1 = ss_error_last_eval_phys_stats(rl1_pkls, eval_len=800, sub_len=400, settle_len=80)\n",
    "mu2, sd2 = ss_error_last_eval_phys_stats(rl2_pkls, eval_len=800, sub_len=400, settle_len=80)\n",
    "\n",
    "print_table_block(mu1, sd1, mu2, sd2, name_out=(\"eta\", \"T\"))"
   ],
   "id": "f206e4c350c3f7fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta:\n",
      "  RL1 mean: SP(a)=0.032, SP(b)=0.007\n",
      "  RL1 std : SP(a)=0.020, SP(b)=0.006\n",
      "  RL2 mean: SP(a)=0.002, SP(b)=0.002\n",
      "  RL2 std : SP(a)=0.003, SP(b)=0.002\n",
      "  Reduction (%): SP(a)=92, SP(b)=76\n",
      "\n",
      "T:\n",
      "  RL1 mean: SP(a)=0.103, SP(b)=0.056\n",
      "  RL1 std : SP(a)=0.133, SP(b)=0.038\n",
      "  RL2 mean: SP(a)=0.016, SP(b)=0.005\n",
      "  RL2 std : SP(a)=0.012, SP(b)=0.005\n",
      "  Reduction (%): SP(a)=84, SP(b)=90\n",
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T04:29:48.891683Z",
     "start_time": "2026-01-08T04:29:48.288098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_dir = compare_three_paths_outputs_only_polymer(\n",
    "    rl1_path=r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist_mpc\\20260107_020146\\input_data.pkl\",\n",
    "    rl2_path=r\"C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\polymer_dist\\20260107_044044\\input_data.pkl\",\n",
    "    mpc_path=mpc_pkl,\n",
    "    directory=dir_path,\n",
    "    prefix_name=\"three_way_compare_dist\",\n",
    "    start_idx=-800,\n",
    "    ylabels=(r\"$\\eta$ (L/g)\", r\"$T$ (K)\"),\n",
    "    save_pdf=True\n",
    ")\n",
    "print(out_dir)"
   ],
   "id": "aa8f22e3398a7fc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAMEDI\\OneDrive - McMaster University\\PythonProjects\\Polymer_example\\Data\\three_way_compare_dist\\20260107_232948\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc11b8f3ba42ebff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
